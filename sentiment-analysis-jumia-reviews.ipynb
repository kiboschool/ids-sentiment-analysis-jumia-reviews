{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Load the product reviews dataset into a variable called `customer_review_df`. Next, write a function called `check_data` to check if the data has been loaded successfully.\n",
    "\n",
    "**Question 1.1:** Explore the distribution of sentiment labels in the dataset.\n",
    "\n",
    "**Question 1.2** Engineer a new feature called `Sentiment` from the _Rating_ column. This takes the values -1, 0, and 1 for `negative`, `neutral`, and `positive`.\n",
    "- Reviews with Rating > 3 is positive\n",
    "- Reviews with Rating = 3 is neutral\n",
    "- Reviews with Rating < 3 is negative"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ASSIGNMENT CONFIG\n",
    "requirements: requirements.txt\n",
    "files:\n",
    "    - sentiment-analysis-jumia-reviews.csv\n",
    "solutions_pdf: false\n",
    "export_cell:\n",
    "    instructions: \"These are some submission instructions.\"\n",
    "generate: \n",
    "    pdf: false\n",
    "    filtering: true\n",
    "    pagebreaks: true\n",
    "    zips: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 8 - Sentiment Analysis of Jumia Reviews\n",
    "\n",
    "Product reviews are evaluations or opinions shared by consumers who have purchased and used a specific product or service. These reviews are typically written on online platforms such as e-commerce websites, social media, or review websites.\n",
    "\n",
    "In this assignment, you will apply your knowledge of sentiment analysis to analyze the sentiments expressed in product reviews by Jumia customers. You will work together as a group to preprocess the text data, build a sentiment analysis model, and interpret the results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "%matplotlib inline\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q1\n",
    "points: 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the customer retention dataset\n",
    "customer_review_df = pd.read_csv('sentiment-analysis-jumia-reviews.csv', engine='python') # SOLUTION\n",
    "\n",
    "# write a function called `check_data` to check data loading is successful\n",
    "def check_data():\n",
    "    # BEGIN SOLUTION\n",
    "    return customer_review_df.empty\n",
    "    # END SOLUTION\n",
    "\n",
    "# Define a function to convert ratings to sentiments\n",
    "def convert_to_sentiment(rating):\n",
    "    # BEGIN SOLUTION\n",
    "    if rating > 3:\n",
    "        return 1  # Positive\n",
    "    elif rating == 3:\n",
    "        return 0  # Neutral\n",
    "    else:\n",
    "        return -1  # Negative\n",
    "    # END SOLUTION\n",
    "\n",
    "# Apply the function to create a 'Sentiment' column\n",
    "customer_review_df['Sentiment'] = customer_review_df['Rating'].apply(convert_to_sentiment)  # SOLUTION\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q2\n",
    "points: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Preprocess the text data by completing the following:\n",
    "- Convert the reviews to lowercase and remove punctuation. \n",
    "- Tokenize the text data to split it into individual words or tokens.\n",
    "\n",
    "**Note**: Assign your final preprocessed dataset to a variable called `processed_customer_review_df`. Failure to do this might result in you not getting a score for this question.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess text data\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()     # SOLUTION\n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])   # SOLUTION\n",
    "    return text\n",
    "\n",
    "# Apply text preprocessing to 'Review' column\n",
    "customer_review_df['Review'] = customer_review_df['Review'].apply(preprocess_text)  # SOLUTION\n",
    "\n",
    "# Tokenize the text data\n",
    "customer_review_df['Tokens'] = customer_review_df['Review'].apply(word_tokenize)    # SOLUTION\n",
    "\n",
    "# Combine tokens into a string (needed for feature extraction)\n",
    "customer_review_df['Tokens'] = customer_review_df['Tokens'].apply(' '.join)     # SOLUTION\n",
    "\n",
    "processed_customer_review_df = customer_review_df       # SOLUTION\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q3\n",
    "points: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Split your processed dataset into training and testing set by using `80:20` rule. You can use **X_train, X_test, y_train, y_test** variable to store your splitted dataset.\n",
    "\n",
    "**Question 3.1:** Choose a feature extraction technique and implement it. You can choose from techniques like `BoW`, `TF-IDF`, or Word Embeddings. Remember to explain your choice.\n",
    "\n",
    "**Question 3.2:** Train the sentiment analysis model using `MultinomialNB()` to analyse the reviews. \n",
    "\n",
    "**Note**: Assign your model to a variable called `sentiment_review_model`. Failure to do this might result in you not getting a score for this question."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_customer_review_df['Tokens'], \n",
    "                                                        processed_customer_review_df['Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a feature extraction technique (e.g., Bag of Words)\n",
    "vectorizer = CountVectorizer(max_features=1000)  # Limit to the top 1000 words\n",
    "X_train_bow = vectorizer.fit_transform(X_train)      # SOLUTION\n",
    "X_test_bow = vectorizer.transform(X_test)            # SOLUTION\n",
    "\n",
    "\n",
    "# Create and train the sentiment analysis model\n",
    "sentiment_review_model = MultinomialNB()            # SOLUTION\n",
    "sentiment_review_model.fit(X_train_bow, y_train)    # SOLUTION\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q4\n",
    "points: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Predict using the developed model and evaluate the model. Evaluate this model using MAE, MSE, RMSE, and R-squared.\n",
    "\n",
    "**Note**: Assign your prediction to a variable called `prediction`. Failure to do this might result in you not getting a score for this question."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# analyse reviews using the model\n",
    "prediction = sentiment_review_model.predict(X_test)      # SOLUTION\n",
    "\n",
    "# evaluate the model using different metrics\n",
    "mae = mean_absolute_error(y_test, prediction)       # SOLUTION\n",
    "mse = mean_squared_error(y_test, prediction)        # SOLUTION\n",
    "rmse = np.sqrt(mse)                                 # SOLUTION\n",
    "r2 = r2_score(y_test, prediction)                   # SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q5\n",
    "points: 1\n",
    "manual: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** What insight can you derive from this data?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
