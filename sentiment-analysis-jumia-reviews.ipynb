{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"sentiment-analysis-jumia-reviews.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 8 - Sentiment Analysis of Jumia Reviews\n",
    "\n",
    "Product reviews are evaluations or opinions shared by consumers who have purchased and used a specific product or service. These reviews are typically written on online platforms such as e-commerce websites, social media, or review websites.\n",
    "\n",
    "In this assignment, you will apply your knowledge of sentiment analysis to analyze the sentiments expressed in product reviews by Jumia customers. You will work together as a group to preprocess the text data, build a sentiment analysis model, and interpret the results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "%matplotlib inline\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Load the product reviews dataset into a variable called `customer_review_df`. Next, write a function called `check_data` to check if the data has been loaded successfully.\n",
    "\n",
    "**Question 1.1:** Explore the distribution of sentiment labels in the dataset.\n",
    "\n",
    "**Question 1.2** Engineer a new feature called `Sentiment` from the _Rating_ column. This takes the values -1, 0, and 1 for `negative`, `neutral`, and `positive`.\n",
    "- Reviews with Rating > 3 is positive\n",
    "- Reviews with Rating = 3 is neutral\n",
    "- Reviews with Rating < 3 is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the customer retention dataset\n",
    "customer_review_df = ...\n",
    "\n",
    "# write a function called `check_data` to check data loading is successful\n",
    "def check_data():\n",
    "    ...\n",
    "\n",
    "# Define a function to convert ratings to sentiments\n",
    "def convert_to_sentiment(rating):\n",
    "    ...\n",
    "\n",
    "# Apply the function to create a 'Sentiment' column\n",
    "customer_review_df['Sentiment'] = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Preprocess the text data by completing the following:\n",
    "- Convert the reviews to lowercase and remove punctuation. \n",
    "- Tokenize the text data to split it into individual words or tokens.\n",
    "\n",
    "**Note**: Assign your final preprocessed dataset to a variable called `processed_customer_review_df`. Failure to do this might result in you not getting a score for this question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess text data\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = ...\n",
    "    # Remove punctuation\n",
    "    text = ...\n",
    "    return text\n",
    "\n",
    "# Apply text preprocessing to 'Review' column\n",
    "customer_review_df['Review'] = ...\n",
    "\n",
    "# Tokenize the text data\n",
    "customer_review_df['Tokens'] = ...\n",
    "\n",
    "# Combine tokens into a string (needed for feature extraction)\n",
    "customer_review_df['Tokens'] = ...\n",
    "\n",
    "processed_customer_review_df = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Split your processed dataset into training and testing set by using `80:20` rule. You can use **X_train, X_test, y_train, y_test** variable to store your splitted dataset.\n",
    "\n",
    "**Question 3.1:** Choose a feature extraction technique and implement it. You can choose from techniques like `BoW`, `TF-IDF`, or Word Embeddings. Remember to explain your choice.\n",
    "\n",
    "**Question 3.2:** Train the sentiment analysis model using `MultinomialNB()` to analyse the reviews. \n",
    "\n",
    "**Note**: Assign your model to a variable called `sentiment_review_model`. Failure to do this might result in you not getting a score for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_customer_review_df['Tokens'], \n",
    "                                                        processed_customer_review_df['Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a feature extraction technique (e.g., Bag of Words)\n",
    "vectorizer = CountVectorizer(max_features=1000)  # Limit to the top 1000 words\n",
    "X_train_bow = ...\n",
    "X_test_bow = ...\n",
    "\n",
    "\n",
    "# Create and train the sentiment analysis model\n",
    "sentiment_review_model = ...\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Predict using the developed model and evaluate the model. Evaluate this model using MAE, MSE, RMSE, and R-squared.\n",
    "\n",
    "**Note**: Assign your prediction to a variable called `prediction`. Failure to do this might result in you not getting a score for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# analyse reviews using the model\n",
    "prediction = ...\n",
    "\n",
    "# evaluate the model using different metrics\n",
    "mae = ...\n",
    "mse = ...\n",
    "rmse = ...\n",
    "r2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 5:** What insight can you derive from this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "These are some submission instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
